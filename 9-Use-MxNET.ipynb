{"cells":[{"cell_type":"markdown","source":["To install MXNet on a single node using the following script (for the community edition because the driver and the worker are on the same node).  \n* Run the script below.\n\n**NOTE: Use an init script to install on a multi-node cluster. Using this script on a multinode cluster will not work, because MXNet will only be installed on the driver.  The init script solves this problem by running the install script when the worker launches. **"],"metadata":{}},{"cell_type":"code","source":["%sh\n\nrm -rf /usr/local/mxnet\n\nmxnetGitTag=\"eaa6253\"\n\nset -ex\n\necho \"**** Installing MXNet dependencies ****\"\n\napt-get update\n\n# Requirements stated in http://mxnet.io/get_started/setup.html#standard-installation.\n# We used OpenBLAS instead of ATLAS.\napt-get install -y build-essential git libopenblas-dev libopencv-dev python-numpy python-setuptools\n\necho \"**** Downloading MXNet ****\"\n\nMXNET_HOME=/usr/local/mxnet\ngit clone --recursive https://github.com/dmlc/mxnet $MXNET_HOME\ncd $MXNET_HOME\ngit checkout ${mxnetGitTag}\ngit submodule update\n\necho \"**** Building MXNet ****\"\n\nUSE_CUDA=0 USE_CUDNN=0 USE_CUDA_PATH=/usr/local/cuda USE_BLAS=openblas make -e -j$(nproc)\n\necho \"**** Installing MXNet ****\"\n\ncd python\npython setup.py install"],"metadata":{},"outputs":[],"execution_count":2},{"cell_type":"markdown","source":["With python, it is normally only necessary to install a module before you can start using it.  However, when working in a notebook, python is already “running”.  So, python will not notice that the MXNet module is available unless you “restart” python.  \n\nThis is simpler than it sounds.  Simply use the cluster menu to `Detach` from your cluster.  Then use the menu again to `Attach` to the cluster.  The notebook will be executed again with a fresh instance of python, and you should be able to import MXNet as you normally would.\n\nTry importing `mxnet` now as `mx`, and `print` `__version__`."],"metadata":{}},{"cell_type":"code","source":["import mxnet as mx\nprint (mx.__version__)"],"metadata":{},"outputs":[],"execution_count":4},{"cell_type":"markdown","source":["With module installation out of the way.  Lets get started by loading some data."],"metadata":{}},{"cell_type":"code","source":["import numpy as np\nimport os\nimport urllib\nimport gzip\nimport struct\n\ndef download_data(url, force_download=True): \n    fname = url.split(\"/\")[-1]\n    if force_download or not os.path.exists(fname):\n        urllib.urlretrieve(url, fname)\n    return fname\n\ndef read_data(label_url, image_url):\n    with gzip.open(download_data(label_url)) as flbl:\n        magic, num = struct.unpack(\">II\", flbl.read(8))\n        label = np.fromstring(flbl.read(), dtype=np.int8)\n    with gzip.open(download_data(image_url), 'rb') as fimg:\n        magic, num, rows, cols = struct.unpack(\">IIII\", fimg.read(16))\n        image = np.fromstring(fimg.read(), dtype=np.uint8).reshape(len(label), rows, cols)\n    return (label, image)\n\npath='http://yann.lecun.com/exdb/mnist/'\n(train_lbl, train_img) = read_data(\n    path+'train-labels-idx1-ubyte.gz', path+'train-images-idx3-ubyte.gz')\n(val_lbl, val_img) = read_data(\n    path+'t10k-labels-idx1-ubyte.gz', path+'t10k-images-idx3-ubyte.gz')"],"metadata":{},"outputs":[],"execution_count":6},{"cell_type":"code","source":["import matplotlib.pyplot as plt\nfor i in range(10):\n    plt.subplot(1,10,i+1)\n    plt.imshow(train_img[i], cmap='Greys_r')\n    plt.axis('off')\nplt.show()\ndisplay()"],"metadata":{},"outputs":[],"execution_count":7},{"cell_type":"code","source":["print('label: %s' % (train_lbl[0:10],))"],"metadata":{},"outputs":[],"execution_count":8},{"cell_type":"markdown","source":["Create data iterators"],"metadata":{}},{"cell_type":"code","source":["def to4d(img):\n    return img.reshape(img.shape[0], 1, 28, 28).astype(np.float32)/255\n\nbatch_size = 100\ntrain_iter = mx.io.NDArrayIter(to4d(train_img), train_lbl, batch_size, shuffle=True)\nval_iter = mx.io.NDArrayIter(to4d(val_img), val_lbl, batch_size)"],"metadata":{},"outputs":[],"execution_count":10},{"cell_type":"markdown","source":["Multilayer Perceptron"],"metadata":{}},{"cell_type":"code","source":["# Create a place holder variable for the input data\ndata = mx.sym.Variable('data')\n# Flatten the data from 4-D shape (batch_size, num_channel, width, height) \n# into 2-D (batch_size, num_channel*width*height)\ndata = mx.sym.Flatten(data=data)\n\n# The first fully-connected layer\nfc1  = mx.sym.FullyConnected(data=data, name='fc1', num_hidden=128)\n# Apply relu to the output of the first fully-connnected layer\nact1 = mx.sym.Activation(data=fc1, name='relu1', act_type=\"relu\")\n\n# The second fully-connected layer and the according activation function\nfc2  = mx.sym.FullyConnected(data=act1, name='fc2', num_hidden = 64)\nact2 = mx.sym.Activation(data=fc2, name='relu2', act_type=\"relu\")\n\n# The thrid fully-connected layer, note that the hidden size should be 10, which is the number of unique digits\nfc3  = mx.sym.FullyConnected(data=act2, name='fc3', num_hidden=10)\n# The softmax and loss layer\nmlp  = mx.sym.SoftmaxOutput(data=fc3, name='softmax')"],"metadata":{},"outputs":[],"execution_count":12},{"cell_type":"markdown","source":["Now both the network definition and data iterators are ready. We can start training."],"metadata":{}},{"cell_type":"code","source":["model = mx.model.FeedForward(\n    symbol = mlp,       # network structure\n    num_epoch = 10,     # number of data passes for training \n    learning_rate = 0.1 # learning rate of SGD \n)\nmodel.fit(\n    X=train_iter,       # training data\n    eval_data=val_iter, # validation data\n    batch_end_callback = mx.callback.Speedometer(batch_size, 200) # output progress for each 200 data batches\n) "],"metadata":{},"outputs":[],"execution_count":14},{"cell_type":"markdown","source":["After training is done, we can predict a single image."],"metadata":{}},{"cell_type":"code","source":["plt.clf()\nplt.imshow(val_img[0], cmap='Greys_r')\nplt.axis('off')\nplt.show()\ndisplay()"],"metadata":{},"outputs":[],"execution_count":16},{"cell_type":"code","source":["prob = model.predict(val_img[0:1].astype(np.float32)/255)[0]\nprint 'Classified as %d with probability %f' % (prob.argmax(), max(prob))"],"metadata":{},"outputs":[],"execution_count":17},{"cell_type":"markdown","source":["We can also evaluate the accuracy by given a data iterator."],"metadata":{}},{"cell_type":"code","source":["print 'Validation accuracy: %f%%' % (model.score(val_iter)*100,)"],"metadata":{},"outputs":[],"execution_count":19},{"cell_type":"markdown","source":["Convolutional Neural Networks"],"metadata":{}},{"cell_type":"code","source":["data = mx.symbol.Variable('data')\n# first conv layer\nconv1 = mx.sym.Convolution(data=data, kernel=(5,5), num_filter=20)\ntanh1 = mx.sym.Activation(data=conv1, act_type=\"tanh\")\npool1 = mx.sym.Pooling(data=tanh1, pool_type=\"max\", kernel=(2,2), stride=(2,2))\n# second conv layer\nconv2 = mx.sym.Convolution(data=pool1, kernel=(5,5), num_filter=50)\ntanh2 = mx.sym.Activation(data=conv2, act_type=\"tanh\")\npool2 = mx.sym.Pooling(data=tanh2, pool_type=\"max\", kernel=(2,2), stride=(2,2))\n# first fullc layer\nflatten = mx.sym.Flatten(data=pool2)\nfc1 = mx.symbol.FullyConnected(data=flatten, num_hidden=500)\ntanh3 = mx.sym.Activation(data=fc1, act_type=\"tanh\")\n# second fullc\nfc2 = mx.sym.FullyConnected(data=tanh3, num_hidden=10)\n# softmax loss\nlenet = mx.sym.SoftmaxOutput(data=fc2, name='softmax')"],"metadata":{},"outputs":[],"execution_count":21},{"cell_type":"markdown","source":["Note that LeNet is more complex than the previous multilayer perceptron, so we use GPU instead of CPU for training.  \nNOTE: This takes up to 45 minute on the community edition - this is the point at which you could integrate with Spark (i.e. via broadcast, etc...)  to optimize."],"metadata":{}},{"cell_type":"code","source":["model = mx.model.FeedForward(\n#     ctx = mx.gpu(0),     # use GPU 0 for training, others are same as before\n    symbol = lenet,       \n    num_epoch = 10,     \n    learning_rate = 0.1)\nmodel.fit(\n    X=train_iter,  \n    eval_data=val_iter, \n    batch_end_callback = mx.callback.Speedometer(batch_size, 200)\n) "],"metadata":{},"outputs":[],"execution_count":23},{"cell_type":"code","source":["print 'Validation accuracy: %f%%' % (model.score(val_iter)*100,)"],"metadata":{},"outputs":[],"execution_count":24}],"metadata":{"name":"9-Use-MxNET","notebookId":2389884582905138},"nbformat":4,"nbformat_minor":0}
